{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Imports",
   "id": "7b4c3b0961ac3b1e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:08:04.315970Z",
     "start_time": "2025-04-25T16:08:04.313208Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm"
   ],
   "id": "f80b91b841340426",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-25T16:08:04.332127Z",
     "start_time": "2025-04-25T16:08:04.329583Z"
    }
   },
   "source": [
    "from nim.Nim import Nim\n",
    "\n",
    "from agents.Minimax.MinimaxAgentV1 import MinimaxAgentV1\n",
    "from agents.Minimax.MinimaxAgentV2 import MinimaxAgentV2\n",
    "\n",
    "from agents.QLearning.QLearningAgentV1 import QLearningAgentV1\n",
    "from agents.QLearning.QLearningAgentV2 import QLearningAgentV2"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "ParametrizedAgent class (helper)",
   "id": "8b6f4ab38e9d516"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:08:04.345733Z",
     "start_time": "2025-04-25T16:08:04.343312Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ParametrizedAgent:\n",
    "    def __init__(self, agent_class, *param_names):\n",
    "        self.agent_class = agent_class\n",
    "        self.param_names = param_names\n",
    "\n",
    "    def __call__(self, **kwargs):\n",
    "        params = {k: v for k, v in kwargs.items() if k in self.param_names}\n",
    "        return self.agent_class(**params)\n",
    "\n",
    "# AGENT = ParametrizedAgent(MinimaxAgentV1, \"misere\", \"max_depth\")\n",
    "# AGENT = ParametrizedAgent(MinimaxAgentV2, \"misere\", \"max_depth\")\n",
    "# AGENT = ParametrizedAgent(QLearningAgentV1, \"misere\", \"max_piles\", \"alpha\", \"epsilon\", \"gamma\", \"decay_rate\")\n",
    "AGENT = ParametrizedAgent(QLearningAgentV2, \"misere\", \"max_piles\", \"alpha\", \"epsilon\", \"gamma\", \"decay_rate\")"
   ],
   "id": "abe2fd3436a584e4",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Constants",
   "id": "6469a4493d07d6a7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:08:04.356474Z",
     "start_time": "2025-04-25T16:08:04.354554Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Game related\n",
    "INITIAL_PILES = [21, 20, 19, 18, 56]\n",
    "MISERE = False\n",
    "\n",
    "# Minimax Agents\n",
    "MAX_DEPTH = 1\n",
    "\n",
    "# QLearning Agents\n",
    "ALPHA = 0.5\n",
    "EPSILLON = 0.1\n",
    "GAMMA = 0.9\n",
    "DECAY_RATE = 0.9999\n",
    "MAX_PILES = [255] * 8"
   ],
   "id": "2734ef9cdbee5047",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Assert function (helper)",
   "id": "9b3d188180eca026"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:08:04.365939Z",
     "start_time": "2025-04-25T16:08:04.363165Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def hard_assert(_misere, _initial_piles, _winner):\n",
    "    piles = np.array(_initial_piles)\n",
    "\n",
    "    if _misere:\n",
    "        if np.all(piles <= 1):\n",
    "            assert _winner == np.sum(piles) % 2, \"Misere Nim - Corner Case\"\n",
    "\n",
    "    else:\n",
    "        assert _winner == int(np.bitwise_xor.reduce(piles) != _misere), f\"{'Misere' if _misere else 'Normal'} Nim - All Cases\"\n",
    "\n",
    "def soft_assert(_misere, _initial_piles, _winner, _wins):\n",
    "    piles = np.array(_initial_piles)\n",
    "    nim_sum = np.bitwise_xor.reduce(piles)\n",
    "\n",
    "    game_type = \"M\" if _misere else \"N\"\n",
    "    start_sum = \"=0\" if int(nim_sum == 0) else \">0\"\n",
    "    p_who_won = \"P\" + str(_winner + 1)\n",
    "\n",
    "    _wins[f\"{game_type}_{start_sum}_{p_who_won}\"] = _wins.get(f\"{game_type}_{start_sum}_{p_who_won}\", 0) + 1"
   ],
   "id": "c3957002d3e11593",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Agent Setup",
   "id": "caee15f67b9ae8b9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:08:09.156642Z",
     "start_time": "2025-04-25T16:08:04.371612Z"
    }
   },
   "cell_type": "code",
   "source": [
    "misereAgent = AGENT(misere=True, max_piles=MAX_PILES, max_depth=MAX_DEPTH)\n",
    "normalAgent = AGENT(misere=False, max_piles=MAX_PILES, max_depth=MAX_DEPTH)"
   ],
   "id": "12377bf62677145b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q-values loaded from savedAgents/qlearningV2-255-255-255-255-255-255-255-255-True.json\n",
      "Q-table dimensions: 1657433\n",
      "Q-values loaded from savedAgents/qlearningV2-255-255-255-255-255-255-255-255-False.json\n",
      "Q-table dimensions: 1657793\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# One game demo",
   "id": "8caf6e9c1c377962"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:08:09.165357Z",
     "start_time": "2025-04-25T16:08:09.163398Z"
    }
   },
   "cell_type": "code",
   "source": [
    "game = Nim(\n",
    "    initial_piles=INITIAL_PILES,\n",
    "    misere=MISERE\n",
    ")\n",
    "\n",
    "winner = game.play(\n",
    "    player1=misereAgent if MISERE else normalAgent,\n",
    "    player2=misereAgent if MISERE else normalAgent\n",
    ")"
   ],
   "id": "f97d02e6c6f50f43",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal game\n",
      "Piles: [21, 20, 19, 18, 56]\n",
      "Player 1 (Q-LearningV2 agent) takes 13 from pile 0\n",
      "Piles: [8, 20, 19, 18, 56]\n",
      "Player 2 (Q-LearningV2 agent) takes 49 from pile 4\n",
      "Piles: [8, 20, 19, 18, 7]\n",
      "Player 1 (Q-LearningV2 agent) takes 3 from pile 3\n",
      "Piles: [8, 20, 19, 15, 7]\n",
      "Player 2 (Q-LearningV2 agent) takes 7 from pile 0\n",
      "Piles: [1, 20, 19, 15, 7]\n",
      "Player 1 (Q-LearningV2 agent) takes 10 from pile 1\n",
      "Piles: [1, 10, 19, 15, 7]\n",
      "Player 2 (Q-LearningV2 agent) takes 10 from pile 2\n",
      "Piles: [1, 10, 9, 15, 7]\n",
      "Player 1 (Q-LearningV2 agent) takes 4 from pile 1\n",
      "Piles: [1, 6, 9, 15, 7]\n",
      "Player 2 (Q-LearningV2 agent) takes 5 from pile 1\n",
      "Piles: [1, 1, 9, 15, 7]\n",
      "Player 1 (Q-LearningV2 agent) takes 1 from pile 1\n",
      "Piles: [1, 0, 9, 15, 7]\n",
      "Player 2 (Q-LearningV2 agent) takes 6 from pile 4\n",
      "Piles: [1, 0, 9, 15, 1]\n",
      "Player 1 (Q-LearningV2 agent) takes 1 from pile 0\n",
      "Piles: [0, 0, 9, 15, 1]\n",
      "Player 2 (Q-LearningV2 agent) takes 4 from pile 3\n",
      "Piles: [0, 0, 9, 11, 1]\n",
      "Player 1 (Q-LearningV2 agent) takes 7 from pile 2\n",
      "Piles: [0, 0, 2, 11, 1]\n",
      "Player 2 (Q-LearningV2 agent) takes 11 from pile 3\n",
      "Piles: [0, 0, 2, 0, 1]\n",
      "Player 1 (Q-LearningV2 agent) takes 1 from pile 2\n",
      "Piles: [0, 0, 1, 0, 1]\n",
      "Player 2 (Q-LearningV2 agent) takes 1 from pile 4\n",
      "Piles: [0, 0, 1, 0, 0]\n",
      "Player 1 (Q-LearningV2 agent) takes 1 from pile 2\n",
      "Player 1 (Q-LearningV2 agent) wins!\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 10k random game test (Misere)",
   "id": "38122e9bb8d5c6dd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:08:14.630597Z",
     "start_time": "2025-04-25T16:08:09.176816Z"
    }
   },
   "cell_type": "code",
   "source": [
    "wins = {}\n",
    "\n",
    "for _ in tqdm(range(10000)):\n",
    "    misere = np.random.choice([True, False])\n",
    "    initial_piles = list(np.random.randint(1, 50, size=8))\n",
    "\n",
    "    game = Nim(\n",
    "        initial_piles=initial_piles,\n",
    "        misere=misere\n",
    "    )\n",
    "\n",
    "    winner = game.play(\n",
    "        player1=misereAgent if MISERE else normalAgent,\n",
    "        player2=misereAgent if MISERE else normalAgent,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # hard_assert(misere, initial_piles, winner)\n",
    "    soft_assert(misere, initial_piles, winner, wins)\n",
    "\n",
    "for k, v in wins.items():\n",
    "    print(f\"{k}: {v}\")"
   ],
   "id": "b1cb07b39efc962a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:05<00:00, 1834.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_>0_P2: 2405\n",
      "M_>0_P1: 2465\n",
      "M_>0_P2: 2548\n",
      "N_>0_P1: 2432\n",
      "M_=0_P1: 41\n",
      "N_=0_P2: 38\n",
      "M_=0_P2: 35\n",
      "N_=0_P1: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:08:14.640593Z",
     "start_time": "2025-04-25T16:08:14.638853Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "da7ed4512a7f5bca",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
