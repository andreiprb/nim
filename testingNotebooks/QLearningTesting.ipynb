{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-15T08:37:06.813606Z",
     "start_time": "2025-07-15T08:37:06.791809Z"
    }
   },
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T08:37:06.846943Z",
     "start_time": "2025-07-15T08:37:06.842400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nim import NimGame\n",
    "from nim import NimLogic\n",
    "\n",
    "from agents import AlgorithmicAgent\n",
    "\n",
    "from agents import QLearningAgent"
   ],
   "id": "1bd72fa4e7d8fc61",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T08:37:06.861422Z",
     "start_time": "2025-07-15T08:37:06.852120Z"
    }
   },
   "cell_type": "code",
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "MAX_PILE = 7\n",
    "PILE_COUNT = 4\n",
    "\n",
    "EPISODES = 1000000"
   ],
   "id": "c289e81ef296a7b6",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T08:37:06.869504Z",
     "start_time": "2025-07-15T08:37:06.866960Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test_agent(_misereAgent, _normalAgent, _misere, _initial_piles, _perfect=False):\n",
    "    for i in tqdm(range(EPISODES)):\n",
    "        game = NimGame(\n",
    "            initial_piles=_initial_piles[i],\n",
    "            misere=_misere[i]\n",
    "        )\n",
    "\n",
    "        agent1 = _misereAgent if _misere[i] else _normalAgent\n",
    "        agent2 = agent1 if _perfect else AlgorithmicAgent(misere=_misere[i])\n",
    "\n",
    "        winner = game.play(\n",
    "            player1=agent1,\n",
    "            player2=agent2,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        \"\"\" AGENT VALIDATION \"\"\"\n",
    "        assert winner == NimLogic.is_p_position(_initial_piles[i], _misere[i]), \"Bad agent!\""
   ],
   "id": "665d19ab38acff1f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T08:37:06.880236Z",
     "start_time": "2025-07-15T08:37:06.877931Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_tests(misere_agents, normal_agents, pile_count, max_pile, episodes, perfect=False):\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"Configuration: pile_count: {pile_count}, max_pile: {max_pile}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    initial_piles = np.random.randint(1, max_pile, size=(episodes, pile_count))\n",
    "    misere_modes = np.random.choice([False, True], size=episodes)\n",
    "\n",
    "    for agent_key in misere_agents.keys():\n",
    "        misere_agent = misere_agents[agent_key]\n",
    "        normal_agent = normal_agents[agent_key]\n",
    "\n",
    "        print(f\"Testing {misere_agent}\")\n",
    "\n",
    "        test_agent(misere_agent, normal_agent, misere_modes, initial_piles, perfect)"
   ],
   "id": "e28b1e0abf0e248f",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T08:37:06.988367Z",
     "start_time": "2025-07-15T08:37:06.886338Z"
    }
   },
   "cell_type": "code",
   "source": [
    "misereAgents = {\n",
    "    'n': QLearningAgent(misere=True, pile_count=PILE_COUNT, max_pile=MAX_PILE, num_episodes=100000),\n",
    "    'c': QLearningAgent(misere=True, pile_count=PILE_COUNT, max_pile=MAX_PILE, num_episodes=10000, canonical=True),\n",
    "    'r': QLearningAgent(misere=True, pile_count=PILE_COUNT, max_pile=MAX_PILE, num_episodes=10000, reduced=True),\n",
    "}\n",
    "\n",
    "normalAgents = {\n",
    "    'n': QLearningAgent(misere=False, pile_count=PILE_COUNT, max_pile=MAX_PILE, num_episodes=100000),\n",
    "    'c': QLearningAgent(misere=False, pile_count=PILE_COUNT, max_pile=MAX_PILE, num_episodes=10000, canonical=True),\n",
    "    'r': QLearningAgent(misere=False, pile_count=PILE_COUNT, max_pile=MAX_PILE, num_episodes=10000, reduced=True),\n",
    "}"
   ],
   "id": "95fa93a9e843055f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded agent from ../savedAgents/QLearning/qlearning-4-7-misere-100000.json\n",
      "QLearning Agent ready. Q-table size: 53374\n",
      "Loaded agent from ../savedAgents/QLearning/qlearning-4-7-misere-canonical-10000.json\n",
      "Canonical QLearning Agent ready. Q-table size: 4420\n",
      "Loaded agent from ../savedAgents/QLearning/qlearning-4-7-misere-reduced-10000.json\n",
      "Reduced QLearning Agent ready. Q-table size: 4438\n",
      "Loaded agent from ../savedAgents/QLearning/qlearning-4-7-normal-100000.json\n",
      "QLearning Agent ready. Q-table size: 53505\n",
      "Loaded agent from ../savedAgents/QLearning/qlearning-4-7-normal-canonical-10000.json\n",
      "Canonical QLearning Agent ready. Q-table size: 4446\n",
      "Loaded agent from ../savedAgents/QLearning/qlearning-4-7-normal-reduced-10000.json\n",
      "Reduced QLearning Agent ready. Q-table size: 4446\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T08:37:07.127719Z",
     "start_time": "2025-07-15T08:37:06.993523Z"
    }
   },
   "cell_type": "code",
   "source": "run_tests(misereAgents, normalAgents, pile_count=PILE_COUNT, max_pile=MAX_PILE, episodes=EPISODES)",
   "id": "9edf08c0b8da22c4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Configuration: pile_count: 4, max_pile: 7\n",
      "------------------------------------------------------------\n",
      "Testing QLearning Agent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "a must be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mrun_tests\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmisereAgents\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnormalAgents\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpile_count\u001B[49m\u001B[43m=\u001B[49m\u001B[43mPILE_COUNT\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_pile\u001B[49m\u001B[43m=\u001B[49m\u001B[43mMAX_PILE\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepisodes\u001B[49m\u001B[43m=\u001B[49m\u001B[43mEPISODES\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 15\u001B[39m, in \u001B[36mrun_tests\u001B[39m\u001B[34m(misere_agents, normal_agents, pile_count, max_pile, episodes, perfect)\u001B[39m\n\u001B[32m     11\u001B[39m normal_agent = normal_agents[agent_key]\n\u001B[32m     13\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mTesting \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmisere_agent\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m15\u001B[39m \u001B[43mtest_agent\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmisere_agent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnormal_agent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmisere_modes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minitial_piles\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mperfect\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 11\u001B[39m, in \u001B[36mtest_agent\u001B[39m\u001B[34m(_misereAgent, _normalAgent, _misere, _initial_piles, _perfect)\u001B[39m\n\u001B[32m      8\u001B[39m agent1 = _misereAgent \u001B[38;5;28;01mif\u001B[39;00m _misere[i] \u001B[38;5;28;01melse\u001B[39;00m _normalAgent\n\u001B[32m      9\u001B[39m agent2 = agent1 \u001B[38;5;28;01mif\u001B[39;00m _perfect \u001B[38;5;28;01melse\u001B[39;00m AlgorithmicAgent(misere=_misere[i])\n\u001B[32m---> \u001B[39m\u001B[32m11\u001B[39m winner = \u001B[43mgame\u001B[49m\u001B[43m.\u001B[49m\u001B[43mplay\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     12\u001B[39m \u001B[43m    \u001B[49m\u001B[43mplayer1\u001B[49m\u001B[43m=\u001B[49m\u001B[43magent1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     13\u001B[39m \u001B[43m    \u001B[49m\u001B[43mplayer2\u001B[49m\u001B[43m=\u001B[49m\u001B[43magent2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     14\u001B[39m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\n\u001B[32m     15\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     17\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\" AGENT VALIDATION \"\"\"\u001B[39;00m\n\u001B[32m     18\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m winner == NimLogic.is_p_position(_initial_piles[i], _misere[i]), \u001B[33m\"\u001B[39m\u001B[33mBad agent!\u001B[39m\u001B[33m\"\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/nim/nim/NimGame.py:41\u001B[39m, in \u001B[36mNimGame.play\u001B[39m\u001B[34m(self, player1, player2, verbose)\u001B[39m\n\u001B[32m     38\u001B[39m current_player = \u001B[38;5;28mself\u001B[39m.player\n\u001B[32m     39\u001B[39m current_agent = players[current_player]\n\u001B[32m---> \u001B[39m\u001B[32m41\u001B[39m pile, count = \u001B[43mcurrent_agent\u001B[49m\u001B[43m.\u001B[49m\u001B[43mchoose_action\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mpiles\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     43\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m verbose:\n\u001B[32m     44\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mPlayer \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mint\u001B[39m(current_player)\u001B[38;5;250m \u001B[39m+\u001B[38;5;250m \u001B[39m\u001B[32m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m (\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcurrent_agent.\u001B[34m__class__\u001B[39m.\u001B[34m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m) takes \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcount\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m from pile \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpile\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/nim/agents/AlgorithmicAgent.py:33\u001B[39m, in \u001B[36mAlgorithmicAgent.choose_action\u001B[39m\u001B[34m(self, state)\u001B[39m\n\u001B[32m     30\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m h ^ xor < h:\n\u001B[32m     31\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m i, \u001B[38;5;28mint\u001B[39m(h - (h ^ xor))\n\u001B[32m---> \u001B[39m\u001B[32m33\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mNimLogic\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrandom_action_from_state\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstate\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/nim/nim/NimLogic.py:23\u001B[39m, in \u001B[36mNimLogic.random_action_from_state\u001B[39m\u001B[34m(state)\u001B[39m\n\u001B[32m     21\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\" Returns a random action based on the current state of the game. \"\"\"\u001B[39;00m\n\u001B[32m     22\u001B[39m actions = NimLogic.available_actions(state)\n\u001B[32m---> \u001B[39m\u001B[32m23\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mNimLogic\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrandom_action\u001B[49m\u001B[43m(\u001B[49m\u001B[43mactions\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/nim/nim/NimLogic.py:17\u001B[39m, in \u001B[36mNimLogic.random_action\u001B[39m\u001B[34m(actions)\u001B[39m\n\u001B[32m     14\u001B[39m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[32m     15\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mrandom_action\u001B[39m(actions: \u001B[38;5;28mset\u001B[39m[\u001B[38;5;28mtuple\u001B[39m[\u001B[38;5;28mint\u001B[39m, \u001B[38;5;28mint\u001B[39m]]) -> \u001B[38;5;28mtuple\u001B[39m[\u001B[38;5;28mint\u001B[39m, \u001B[38;5;28mint\u001B[39m]:\n\u001B[32m     16\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\" Returns a random action from the list of available actions. \"\"\"\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m17\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mnp\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrandom\u001B[49m\u001B[43m.\u001B[49m\u001B[43mchoice\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mactions\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mnumpy/random/mtrand.pyx:970\u001B[39m, in \u001B[36mnumpy.random.mtrand.RandomState.choice\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[31mValueError\u001B[39m: a must be 1-dimensional"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "run_tests(misereAgents, normalAgents, pile_count=PILE_COUNT, max_pile=MAX_PILE, episodes=EPISODES, perfect=True)",
   "id": "b2c1d369d2d052e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "404c376b1c1e31d8",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
