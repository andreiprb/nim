{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-11T11:22:53.488127Z",
     "start_time": "2025-07-11T11:22:53.479015Z"
    }
   },
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T11:22:53.560992Z",
     "start_time": "2025-07-11T11:22:53.558850Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from Nim.Nim import Nim\n",
    "from Nim.NimLogic import NimLogic\n",
    "\n",
    "from Agents.QLearningAgent import QLearningAgent"
   ],
   "id": "1bd72fa4e7d8fc61",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T11:22:53.564059Z",
     "start_time": "2025-07-11T11:22:53.562555Z"
    }
   },
   "cell_type": "code",
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "MAX_PILE = 7\n",
    "PILE_COUNT = 4\n",
    "\n",
    "EPISODES = 1000000"
   ],
   "id": "c289e81ef296a7b6",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T11:22:53.570572Z",
     "start_time": "2025-07-11T11:22:53.568862Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test_agent(_misereAgent, _normalAgent, _misere, _initial_piles):\n",
    "    for i in tqdm(range(EPISODES)):\n",
    "        game = Nim(\n",
    "            initial_piles=_initial_piles[i],\n",
    "            misere=_misere[i]\n",
    "        )\n",
    "\n",
    "        agent = _misereAgent if _misere[i] else _normalAgent\n",
    "\n",
    "        winner = game.play(\n",
    "            player1=agent,\n",
    "            player2=agent,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        \"\"\" AGENT VALIDATION \"\"\"\n",
    "        assert winner == NimLogic.is_p_position(_initial_piles[i], _misere[i]), \"Bad agent!\""
   ],
   "id": "665d19ab38acff1f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T11:22:53.577478Z",
     "start_time": "2025-07-11T11:22:53.575781Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_tests(misere_agents, normal_agents, pile_count, max_pile, episodes):\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"Configuration: pile_count: {pile_count}, max_pile: {max_pile}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    initial_piles = np.random.randint(1, max_pile, size=(episodes, pile_count))\n",
    "    misere_modes = np.random.choice([True], size=episodes)\n",
    "\n",
    "    for agent_key in misere_agents.keys():\n",
    "        misere_agent = misere_agents[agent_key]\n",
    "        normal_agent = normal_agents[agent_key]\n",
    "\n",
    "        print(f\"Testing {misere_agent}\")\n",
    "\n",
    "        test_agent(misere_agent, normal_agent, misere_modes, initial_piles)"
   ],
   "id": "e28b1e0abf0e248f",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T11:22:53.583590Z",
     "start_time": "2025-07-11T11:22:53.581289Z"
    }
   },
   "cell_type": "code",
   "source": [
    "misereAgents = {\n",
    "    # 'n': QLearningAgent(misere=True, pile_count=PILE_COUNT, max_pile=MAX_PILE, num_episodes=100000),\n",
    "    # 'c': QLearningAgent(misere=True, pile_count=PILE_COUNT, max_pile=MAX_PILE, num_episodes=10000, canonical=True),\n",
    "    'r': QLearningAgent(misere=True, pile_count=PILE_COUNT, max_pile=MAX_PILE, num_episodes=1000, reduced=True)\n",
    "}\n",
    "\n",
    "normalAgents = {\n",
    "    # 'n': QLearningAgent(misere=False, pile_count=PILE_COUNT, max_pile=MAX_PILE, num_episodes=100000),\n",
    "    # 'c': QLearningAgent(misere=False, pile_count=PILE_COUNT, max_pile=MAX_PILE, num_episodes=10000, canonical=True),\n",
    "    'r': QLearningAgent(misere=False, pile_count=PILE_COUNT, max_pile=MAX_PILE, num_episodes=1000, reduced=True)\n",
    "}"
   ],
   "id": "95fa93a9e843055f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded agent from ../savedAgents/QLearning/qlearning-4-7-misere-reduced-1000.json\n",
      "Reduced QLearning Agent ready. Q-table size: 185\n",
      "Loaded agent from ../savedAgents/QLearning/qlearning-4-7-normal-reduced-1000.json\n",
      "Reduced QLearning Agent ready. Q-table size: 192\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T11:22:53.696786Z",
     "start_time": "2025-07-11T11:22:53.587887Z"
    }
   },
   "cell_type": "code",
   "source": "run_tests(misereAgents, normalAgents, pile_count=PILE_COUNT, max_pile=MAX_PILE, episodes=EPISODES)",
   "id": "9edf08c0b8da22c4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Configuration: pile_count: 4, max_pile: 7\n",
      "------------------------------------------------------------\n",
      "Testing Reduced QLearning Agent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000000 [00:00<11:46, 1414.61it/s]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Bad agent!",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAssertionError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mrun_tests\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmisereAgents\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnormalAgents\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpile_count\u001B[49m\u001B[43m=\u001B[49m\u001B[43mPILE_COUNT\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_pile\u001B[49m\u001B[43m=\u001B[49m\u001B[43mMAX_PILE\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepisodes\u001B[49m\u001B[43m=\u001B[49m\u001B[43mEPISODES\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 15\u001B[39m, in \u001B[36mrun_tests\u001B[39m\u001B[34m(misere_agents, normal_agents, pile_count, max_pile, episodes)\u001B[39m\n\u001B[32m     11\u001B[39m normal_agent = normal_agents[agent_key]\n\u001B[32m     13\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mTesting \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmisere_agent\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m15\u001B[39m \u001B[43mtest_agent\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmisere_agent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnormal_agent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmisere_modes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minitial_piles\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 17\u001B[39m, in \u001B[36mtest_agent\u001B[39m\u001B[34m(_misereAgent, _normalAgent, _misere, _initial_piles)\u001B[39m\n\u001B[32m     10\u001B[39m winner = game.play(\n\u001B[32m     11\u001B[39m     player1=agent,\n\u001B[32m     12\u001B[39m     player2=agent,\n\u001B[32m     13\u001B[39m     verbose=\u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m     14\u001B[39m )\n\u001B[32m     16\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\" AGENT VALIDATION \"\"\"\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m17\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m winner == NimLogic.is_p_position(_initial_piles[i], _misere[i]), \u001B[33m\"\u001B[39m\u001B[33mBad agent!\u001B[39m\u001B[33m\"\u001B[39m\n",
      "\u001B[31mAssertionError\u001B[39m: Bad agent!"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "695bfbbda65bacaa",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
