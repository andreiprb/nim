{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-07T13:23:17.698830Z",
     "start_time": "2025-07-07T13:23:17.680854Z"
    }
   },
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T13:23:17.709273Z",
     "start_time": "2025-07-07T13:23:17.703941Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from Nim.Nim import Nim\n",
    "from Nim.NimLogic import NimLogic\n",
    "\n",
    "from Agents.QLearningAgent import QLearningAgent"
   ],
   "id": "1bd72fa4e7d8fc61",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T13:23:17.800183Z",
     "start_time": "2025-07-07T13:23:17.798740Z"
    }
   },
   "cell_type": "code",
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "MAX_PILE = 7\n",
    "PILE_COUNT = 4\n",
    "\n",
    "EPISODES = 1000000"
   ],
   "id": "c289e81ef296a7b6",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T13:23:17.810286Z",
     "start_time": "2025-07-07T13:23:17.808178Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test_agent(_misereAgent, _normalAgent, _misere, _initial_piles):\n",
    "    for i in tqdm(range(EPISODES)):\n",
    "        game = Nim(\n",
    "            initial_piles=_initial_piles[i],\n",
    "            misere=_misere[i]\n",
    "        )\n",
    "\n",
    "        agent = _misereAgent if _misere[i] else _normalAgent\n",
    "\n",
    "        winner = game.play(\n",
    "            player1=agent,\n",
    "            player2=agent,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        \"\"\" AGENT VALIDATION \"\"\"\n",
    "        assert winner == NimLogic.is_p_position(_initial_piles[i], _misere[i]), \"Bad agent!\""
   ],
   "id": "665d19ab38acff1f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T13:23:17.815249Z",
     "start_time": "2025-07-07T13:23:17.812817Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_tests(misere_agents, normal_agents, pile_count, max_pile, episodes):\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    initial_piles = np.random.randint(1, max_pile, size=(episodes, pile_count))\n",
    "\n",
    "    print(f\"Configuration: pile_count: {pile_count}, max_pile: {max_pile}\")\n",
    "\n",
    "    print(\"-\" * 60)\n",
    "    misere_modes = np.random.choice([True, False], size=episodes)\n",
    "\n",
    "    for agent_key in misere_agents.keys():\n",
    "        misere_agent = misere_agents[agent_key]\n",
    "        normal_agent = normal_agents[agent_key]\n",
    "\n",
    "        test_agent(misere_agent, normal_agent, misere_modes, initial_piles)"
   ],
   "id": "e28b1e0abf0e248f",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T13:23:31.687133Z",
     "start_time": "2025-07-07T13:23:17.823826Z"
    }
   },
   "cell_type": "code",
   "source": [
    "misereAgents = {\n",
    "    'n': QLearningAgent(misere=True, pile_count=PILE_COUNT, max_pile=MAX_PILE, num_episodes=100000),\n",
    "    'c': QLearningAgent(misere=True, pile_count=PILE_COUNT, max_pile=MAX_PILE, num_episodes=10000, canonical=True),\n",
    "    'r': QLearningAgent(misere=True, pile_count=PILE_COUNT, max_pile=MAX_PILE, num_episodes=1000, reduced=True)\n",
    "}\n",
    "\n",
    "normalAgents = {\n",
    "    'n': QLearningAgent(misere=False, pile_count=PILE_COUNT, max_pile=MAX_PILE, num_episodes=100000),\n",
    "    'c': QLearningAgent(misere=False, pile_count=PILE_COUNT, max_pile=MAX_PILE, num_episodes=10000, canonical=True),\n",
    "    'r': QLearningAgent(misere=False, pile_count=PILE_COUNT, max_pile=MAX_PILE, num_episodes=1000, reduced=True)\n",
    "}"
   ],
   "id": "95fa93a9e843055f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:12<00:00, 8159.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved agent to ../savedAgents/QLearning/qlearning-4-7-misere-100000.json\n",
      "Agent ready. Q-table size: 53374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:01<00:00, 7455.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved agent to ../savedAgents/QLearning/qlearning-4-7-misere-canonical-10000.json\n",
      "Agent ready. Q-table size: 4420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'QLearningAgent' object has no attribute 'random_action'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAttributeError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[6]\u001B[39m\u001B[32m, line 4\u001B[39m\n\u001B[32m      1\u001B[39m misereAgents = {\n\u001B[32m      2\u001B[39m     \u001B[33m'\u001B[39m\u001B[33mn\u001B[39m\u001B[33m'\u001B[39m: QLearningAgent(misere=\u001B[38;5;28;01mTrue\u001B[39;00m, pile_count=PILE_COUNT, max_pile=MAX_PILE, num_episodes=\u001B[32m100000\u001B[39m),\n\u001B[32m      3\u001B[39m     \u001B[33m'\u001B[39m\u001B[33mc\u001B[39m\u001B[33m'\u001B[39m: QLearningAgent(misere=\u001B[38;5;28;01mTrue\u001B[39;00m, pile_count=PILE_COUNT, max_pile=MAX_PILE, num_episodes=\u001B[32m10000\u001B[39m, canonical=\u001B[38;5;28;01mTrue\u001B[39;00m),\n\u001B[32m----> \u001B[39m\u001B[32m4\u001B[39m     \u001B[33m'\u001B[39m\u001B[33mr\u001B[39m\u001B[33m'\u001B[39m: \u001B[43mQLearningAgent\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmisere\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpile_count\u001B[49m\u001B[43m=\u001B[49m\u001B[43mPILE_COUNT\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_pile\u001B[49m\u001B[43m=\u001B[49m\u001B[43mMAX_PILE\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_episodes\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m1000\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreduced\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m      5\u001B[39m }\n\u001B[32m      7\u001B[39m normalAgents = {\n\u001B[32m      8\u001B[39m     \u001B[33m'\u001B[39m\u001B[33mn\u001B[39m\u001B[33m'\u001B[39m: QLearningAgent(misere=\u001B[38;5;28;01mFalse\u001B[39;00m, pile_count=PILE_COUNT, max_pile=MAX_PILE, num_episodes=\u001B[32m100000\u001B[39m),\n\u001B[32m      9\u001B[39m     \u001B[33m'\u001B[39m\u001B[33mc\u001B[39m\u001B[33m'\u001B[39m: QLearningAgent(misere=\u001B[38;5;28;01mFalse\u001B[39;00m, pile_count=PILE_COUNT, max_pile=MAX_PILE, num_episodes=\u001B[32m10000\u001B[39m, canonical=\u001B[38;5;28;01mTrue\u001B[39;00m),\n\u001B[32m     10\u001B[39m     \u001B[33m'\u001B[39m\u001B[33mr\u001B[39m\u001B[33m'\u001B[39m: QLearningAgent(misere=\u001B[38;5;28;01mFalse\u001B[39;00m, pile_count=PILE_COUNT, max_pile=MAX_PILE, num_episodes=\u001B[32m1000\u001B[39m, reduced=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m     11\u001B[39m }\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/nim/Agents/QLearningAgent.py:35\u001B[39m, in \u001B[36mQLearningAgent.__init__\u001B[39m\u001B[34m(self, misere, pile_count, max_pile, num_episodes, override, alpha, epsilon, gamma, canonical, reduced)\u001B[39m\n\u001B[32m     32\u001B[39m \u001B[38;5;28mself\u001B[39m.save_path = os.path.join(\u001B[38;5;28mself\u001B[39m.save_dir, \u001B[38;5;28mself\u001B[39m.filename)\n\u001B[32m     34\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m._load() \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m override:\n\u001B[32m---> \u001B[39m\u001B[32m35\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnum_episodes\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     36\u001B[39m     \u001B[38;5;28mself\u001B[39m._save()\n\u001B[32m     38\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mAgent ready. Q-table size: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m.q)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/nim/Agents/QLearningAgent.py:125\u001B[39m, in \u001B[36mQLearningAgent.train\u001B[39m\u001B[34m(self, num_episodes)\u001B[39m\n\u001B[32m    123\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.reduced:\n\u001B[32m    124\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m NimLogic.is_p_position(current_piles, \u001B[38;5;28mself\u001B[39m.misere):\n\u001B[32m--> \u001B[39m\u001B[32m125\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mrandom_action\u001B[49m(NimLogic.available_actions(current_piles), \u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m    127\u001B[39m     current_piles, index_mapping = NimLogic.reduce_state(current_piles, index_mapping)\n\u001B[32m    129\u001B[39m actions = \u001B[38;5;28mlist\u001B[39m(NimLogic.available_actions(current_piles))\n",
      "\u001B[31mAttributeError\u001B[39m: 'QLearningAgent' object has no attribute 'random_action'"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "run_tests(misereAgents, normalAgents, pile_count=PILE_COUNT, max_pile=MAX_PILE, episodes=EPISODES)",
   "id": "9edf08c0b8da22c4",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
